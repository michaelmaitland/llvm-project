; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 5
; RUN: llc -mtriple=riscv32 -mattr=+v,+m -global-isel -global-isel-abort=1 < %s 2>&1 | FileCheck %s --check-prefixes=RV32
; RUN: llc -mtriple=riscv64 -mattr=+v,+m -global-isel -global-isel-abort=1 < %s 2>&1 | FileCheck %s --check-prefixes=RV64

define i32 @urem_by_vscale_i32(i32 noundef %n) {
; RV32-LABEL: urem_by_vscale_i32:
; RV32:       # %bb.0:
; RV32-NEXT:    csrr a1, vlenb
; RV32-NEXT:    srli a1, a1, 3
; RV32-NEXT:    slli a1, a1, 2
; RV32-NEXT:    addi a1, a1, -1
; RV32-NEXT:    and a0, a0, a1
; RV32-NEXT:    ret
;
; RV64-LABEL: urem_by_vscale_i32:
; RV64:       # %bb.0:
; RV64-NEXT:    csrr a1, vlenb
; RV64-NEXT:    srli a1, a1, 3
; RV64-NEXT:    slli a1, a1, 2
; RV64-NEXT:    addiw a1, a1, -1
; RV64-NEXT:    and a0, a0, a1
; RV64-NEXT:    ret
    %2 = call i32 @llvm.vscale.i64()
    %3 = mul i32 %2, 4
    %4 = urem i32 %n, %3
    ret i32 %4
}

define i64 @urem_by_vscale_i64(i64 noundef %n) {
; RV32-LABEL: urem_by_vscale_i64:
; RV32:       # %bb.0:
; RV32-NEXT:    csrr a2, vlenb
; RV32-NEXT:    srli a2, a2, 3
; RV32-NEXT:    li a3, 1
; RV32-NEXT:    mulhu a3, a2, a3
; RV32-NEXT:    add a3, zero, a3
; RV32-NEXT:    slli a4, a2, 2
; RV32-NEXT:    slli a3, a3, 2
; RV32-NEXT:    srli a2, a2, 30
; RV32-NEXT:    or a2, a3, a2
; RV32-NEXT:    addi a4, a4, -1
; RV32-NEXT:    sltiu a3, a4, -1
; RV32-NEXT:    addi a2, a2, -1
; RV32-NEXT:    add a2, a2, a3
; RV32-NEXT:    and a0, a0, a4
; RV32-NEXT:    and a1, a1, a2
; RV32-NEXT:    ret
;
; RV64-LABEL: urem_by_vscale_i64:
; RV64:       # %bb.0:
; RV64-NEXT:    csrr a1, vlenb
; RV64-NEXT:    srli a1, a1, 3
; RV64-NEXT:    slli a1, a1, 2
; RV64-NEXT:    addi a1, a1, -1
; RV64-NEXT:    and a0, a0, a1
; RV64-NEXT:    ret
    %2 = call i64 @llvm.vscale.i64()
    %3 = mul i64 %2, 4
    %4 = urem i64 %n, %3
    ret i64 %4
}
